{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\axelb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('fr_core_news_md')\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from collections import Counter\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "jar = 'stanford_tagger/stanford-postagger-3.9.2.jar'\n",
    "model = 'stanford_tagger/models/french.tagger'\n",
    "import os\n",
    "java_path = \"C:/Program Files (x86)/Java/jre1.8.0_251/bin/java.exe\"\n",
    "os.environ['JAVAHOME'] = java_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Suicides_wikipedia_scrapping_fr_LEMMATISER.csv',encoding='utf-8',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Content_Lemmatiser_No_Stop_Words=[re.sub(\"', '\",' ',el) for el in data.Content_Lemmatiser_No_Stop_Words]\n",
    "data.Content_Lemmatiser_No_Stop_Words=[re.sub(\"\\['\",'',el) for el in data.Content_Lemmatiser_No_Stop_Words]\n",
    "data.Content_Lemmatiser_No_Stop_Words=[re.sub(\"'\\]\",'',el) for el in data.Content_Lemmatiser_No_Stop_Words]\n",
    "data.Content_Lemmatiser_No_Stop_Words=[el.split(' ') for el in data.Content_Lemmatiser_No_Stop_Words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Carrière',\n",
       " 'artistique',\n",
       " 'Artiste',\n",
       " 'multidisciplinaire',\n",
       " 'peinture',\n",
       " 'sculpture',\n",
       " 'photographie',\n",
       " 'vidéo',\n",
       " 'il',\n",
       " 'enseigne',\n",
       " 'dans',\n",
       " 'différentes',\n",
       " 'écoles',\n",
       " 'de',\n",
       " 'Tel',\n",
       " 'Aviv',\n",
       " 'depuis',\n",
       " '1993',\n",
       " 'Il',\n",
       " 'est',\n",
       " 'récompensé',\n",
       " 'par',\n",
       " 'le',\n",
       " 'prix',\n",
       " 'du',\n",
       " 'Ministère',\n",
       " 'de',\n",
       " 'l',\n",
       " 'Éducation',\n",
       " 'et',\n",
       " 'de',\n",
       " 'la',\n",
       " 'Culture',\n",
       " '2003',\n",
       " 'et',\n",
       " 'le',\n",
       " 'prix',\n",
       " 'du',\n",
       " 'musée',\n",
       " 'd',\n",
       " 'art',\n",
       " 'de',\n",
       " 'Petah',\n",
       " 'Tikva',\n",
       " '2006',\n",
       " 'Ses',\n",
       " 'œuvres',\n",
       " 'sont',\n",
       " 'présentées',\n",
       " 'dans',\n",
       " 'différents',\n",
       " 'musées',\n",
       " 'dont',\n",
       " 'le',\n",
       " 'musée',\n",
       " 'd',\n",
       " 'Israël',\n",
       " 'à',\n",
       " 'Jérusalem',\n",
       " 'Mort',\n",
       " 'Le',\n",
       " '1er',\n",
       " 'février',\n",
       " '2018',\n",
       " 'le',\n",
       " 'site',\n",
       " 'd',\n",
       " 'informations',\n",
       " 'Mako',\n",
       " 'révèle',\n",
       " 'qu',\n",
       " 'il',\n",
       " 'est',\n",
       " 'visé',\n",
       " 'par',\n",
       " 'une',\n",
       " 'enquête',\n",
       " 'concernant',\n",
       " 'des',\n",
       " 'relations',\n",
       " 'sexuelles',\n",
       " 'qu',\n",
       " 'il',\n",
       " 'aurait',\n",
       " 'eues',\n",
       " 'avec',\n",
       " 'des',\n",
       " 'élèves',\n",
       " 'mineures',\n",
       " 'Le',\n",
       " 'lendemain',\n",
       " 'il',\n",
       " 'est',\n",
       " 'retrouvé',\n",
       " 'mort',\n",
       " 'chez',\n",
       " 'lui',\n",
       " 'apparemment',\n",
       " 'suicidé']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Content[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Carrière',\n",
       " 'artistique',\n",
       " 'Artiste',\n",
       " 'multidisciplinaire',\n",
       " 'peinture',\n",
       " 'sculpture',\n",
       " 'photographie',\n",
       " 'vidéo',\n",
       " 'il',\n",
       " 'enseigne',\n",
       " 'dans',\n",
       " 'différentes',\n",
       " 'écoles',\n",
       " 'de',\n",
       " 'Tel',\n",
       " 'Aviv',\n",
       " 'depuis',\n",
       " '1993',\n",
       " 'Il',\n",
       " 'est',\n",
       " 'récompensé',\n",
       " 'par',\n",
       " 'le',\n",
       " 'prix',\n",
       " 'du',\n",
       " 'Ministère',\n",
       " 'de',\n",
       " 'l',\n",
       " 'Éducation',\n",
       " 'et',\n",
       " 'de',\n",
       " 'la',\n",
       " 'Culture',\n",
       " '2003',\n",
       " 'et',\n",
       " 'le',\n",
       " 'prix',\n",
       " 'du',\n",
       " 'musée',\n",
       " 'd',\n",
       " 'art',\n",
       " 'de',\n",
       " 'Petah',\n",
       " 'Tikva',\n",
       " '2006',\n",
       " 'Ses',\n",
       " 'œuvres',\n",
       " 'sont',\n",
       " 'présentées',\n",
       " 'dans',\n",
       " 'différents',\n",
       " 'musées',\n",
       " 'dont',\n",
       " 'le',\n",
       " 'musée',\n",
       " 'd',\n",
       " 'Israël',\n",
       " 'à',\n",
       " 'Jérusalem',\n",
       " 'Mort',\n",
       " 'Le',\n",
       " '1er',\n",
       " 'février',\n",
       " '2018',\n",
       " 'le',\n",
       " 'site',\n",
       " 'd',\n",
       " 'informations',\n",
       " 'Mako',\n",
       " 'révèle',\n",
       " 'qu',\n",
       " 'il',\n",
       " 'est',\n",
       " 'visé',\n",
       " 'par',\n",
       " 'une',\n",
       " 'enquête',\n",
       " 'concernant',\n",
       " 'des',\n",
       " 'relations',\n",
       " 'sexuelles',\n",
       " 'qu',\n",
       " 'il',\n",
       " 'aurait',\n",
       " 'eues',\n",
       " 'avec',\n",
       " 'des',\n",
       " 'élèves',\n",
       " 'mineures',\n",
       " 'Le',\n",
       " 'lendemain',\n",
       " 'il',\n",
       " 'est',\n",
       " 'retrouvé',\n",
       " 'mort',\n",
       " 'chez',\n",
       " 'lui',\n",
       " 'apparemment',\n",
       " 'suicidé']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Content[1].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-2d431ebbf7a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mContent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mContent\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-48-2d431ebbf7a0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mContent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mContent\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "data.Content=[el.split(' ') for el in data.Content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['carrière',\n",
       " 'artistique',\n",
       " 'artiste',\n",
       " 'multidisciplinaire',\n",
       " 'peinture',\n",
       " 'sculpture',\n",
       " 'photographie',\n",
       " 'vidéo',\n",
       " 'enseigne',\n",
       " 'différent',\n",
       " 'école',\n",
       " 'tel',\n",
       " 'aviv',\n",
       " 'depuis',\n",
       " '1993',\n",
       " 'récompenser',\n",
       " 'prix',\n",
       " 'ministère',\n",
       " 'éducation',\n",
       " 'culture',\n",
       " '2003',\n",
       " 'prix',\n",
       " 'musée',\n",
       " 'art',\n",
       " 'Petah',\n",
       " 'Tikva',\n",
       " '2006',\n",
       " 'œuvre',\n",
       " 'présenter',\n",
       " 'différent',\n",
       " 'musée',\n",
       " 'dont',\n",
       " 'musée',\n",
       " 'israël',\n",
       " 'Jérusalem',\n",
       " 'mort',\n",
       " 'premier',\n",
       " 'février',\n",
       " '2018',\n",
       " 'site',\n",
       " 'information',\n",
       " 'Mako',\n",
       " 'révéler',\n",
       " 'viser',\n",
       " 'enquête',\n",
       " 'concerner',\n",
       " 'relation',\n",
       " 'sexuel',\n",
       " 'élève',\n",
       " 'mineur',\n",
       " 'lendemain',\n",
       " 'retrouver',\n",
       " 'mort',\n",
       " 'chez',\n",
       " 'apparemment',\n",
       " 'suicider']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Content_Lemmatiser_No_Stop_Words[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\axelb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\axelb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data.Content)):\n",
    "    if not pd.isnull(data.Content[i]):\n",
    "        data.Content[i]=re.sub('modifier le code ','',data.Content[i])\n",
    "        data.Content[i]=data.Content[i].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tmp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-1a0126add4ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpos_tagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStanfordPOSTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpos_tagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tmp' is not defined"
     ]
    }
   ],
   "source": [
    "pos_tagger = StanfordPOSTagger(model, jar, encoding='utf8' )\n",
    "res = pos_tagger.tag(tmp)\n",
    "print (res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "2094    False\n",
       "2095     True\n",
       "2096     True\n",
       "2097    False\n",
       "2098    False\n",
       "Name: Content, Length: 2099, dtype: bool"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(data.Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-72-02909fede822>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-72-02909fede822>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    data.Content=[pos_tagger.tag(el) for el in data.Content if el not pd.isnull(el)]\u001b[0m\n\u001b[1;37m                                                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "#data.Content_Lemmatiser_No_Stop_Words=[pos_tagger.tag(el) for el in data.Content_Lemmatiser_No_Stop_Words]\n",
    "data.Content=[pos_tagger.tag(el) for el in data.Content if el not pd.isnull(el)]\n",
    "print(\"Temps d execution : %s secondes ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [(fils, NC), (Adolfo, NPP), (couve, V), (Braga...\n",
       "1       [(carrière, NC), (artistique, ADJ), (artiste, ...\n",
       "2       [(originaire, ADJ), (kansa, NC), (city, NPP), ...\n",
       "3       [(section, NC), (vide, NC), (détaillée, ADJ), ...\n",
       "4       [(Michel, NPP), (caron, NC), (vouloir, VINF), ...\n",
       "                              ...                        \n",
       "2094    [(tragique, ADJ), (œuvre, NC), (kazan, ADJ), (...\n",
       "2095                                           [([], NC)]\n",
       "2096                                           [([], NC)]\n",
       "2097    [(naître, VINF), (Sunpu, NPP), (humble, ADJ), ...\n",
       "2098    [(Zusho, NPP), (naître, VINF), (ville, NC), (c...\n",
       "Name: Content_Lemmatiser_No_Stop_Words, Length: 2099, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Content_Lemmatiser_No_Stop_Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeped=['NC','N','NPP','ADJ','V','VINF']\n",
    "tri=[\"l'\",'d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d execution : 0.16034340858459473 secondes ---\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "data.Content_Lemmatiser_No_Stop_Words=[ [el for el in tmp if el[1] in keeped] for tmp in data.Content_Lemmatiser_No_Stop_Words]\n",
    "data.Content_Lemmatiser_No_Stop_Words=[ [el for el in tmp if el[0] not in tri] for tmp in data.Content_Lemmatiser_No_Stop_Words]\n",
    "print(\"Temps d execution : %s secondes ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.Content_Lemmatiser_No_Stop_Words=[[el[0] for el in arr] for arr in data.Content_Lemmatiser_No_Stop_Words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=[\"'\",'section','vide','detaillé','incompléte','aide','bienvenue','faire','avoir',\"r\\'\",\"s\\'\",\"d\\'\",\"qu\\'\",\"l\\'\",'année','premier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'\n"
     ]
    }
   ],
   "source": [
    "te=[\"d\\'\",\"qu\\'\",\"d'\",\"l'\",\"l'\"]\n",
    "for i in range(len(te)):\n",
    "    if te[i]  not in stop_words:\n",
    "        print(te[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fils',\n",
       " 'Adolfo',\n",
       " 'couve',\n",
       " 'Braga',\n",
       " 'Clemencia',\n",
       " 'Rioseco',\n",
       " 'Fernández',\n",
       " 'Adolfo',\n",
       " 'couve',\n",
       " 'aîner',\n",
       " 'frère',\n",
       " 'naître',\n",
       " 'Valparaíso',\n",
       " 'passer',\n",
       " 'enfance',\n",
       " 'Llay',\n",
       " 'Llay',\n",
       " 'habite',\n",
       " 'âge',\n",
       " 'huit',\n",
       " 'an',\n",
       " 'installer',\n",
       " 'famille',\n",
       " 'santiago',\n",
       " 'Chile',\n",
       " 'achever',\n",
       " 'scolarité',\n",
       " 'Colegio',\n",
       " 'enterprend',\n",
       " 'étude',\n",
       " 'artistique',\n",
       " 'escuela',\n",
       " 'Bellas',\n",
       " 'Artes',\n",
       " 'obtenir',\n",
       " 'bourse',\n",
       " 'étudier',\n",
       " 'beal',\n",
       " 'art',\n",
       " 'Paris',\n",
       " 'suivre',\n",
       " 'poursuivre',\n",
       " 'étude',\n",
       " 'art',\n",
       " 'student',\n",
       " 'marier',\n",
       " 'Marta',\n",
       " 'Carrasco',\n",
       " 'peintre',\n",
       " 'illustrateur',\n",
       " 'livre',\n",
       " 'enfer',\n",
       " 'fille',\n",
       " 'Camila',\n",
       " 'couve',\n",
       " 'fait',\n",
       " 'débute',\n",
       " 'écriture',\n",
       " 'publier',\n",
       " 'estampa',\n",
       " 'niña',\n",
       " 'Alfaguara',\n",
       " 'passer',\n",
       " 'dernier',\n",
       " 'vie',\n",
       " 'Carthagène',\n",
       " 'petit',\n",
       " 'ville',\n",
       " 'province',\n",
       " 'saint',\n",
       " 'fort',\n",
       " 'dépression',\n",
       " 'suicide']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "save=data.Content_Lemmatiser_No_Stop_Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\axelb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "tmp=data.Content_Lemmatiser_No_Stop_Words\n",
    "data.Content_Lemmatiser_No_Stop_Words=[[el for el in arr if el not in stop_words] for arr in data.Content_Lemmatiser_No_Stop_Words]\n",
    "for arr in range(len(data.Content_Lemmatiser_No_Stop_Words)):\n",
    "    tmp_arr=[]\n",
    "    for el in range(len(data.Content_Lemmatiser_No_Stop_Words[arr])):\n",
    "        if not data.Content_Lemmatiser_No_Stop_Words[arr][el].isdigit():\n",
    "            tmp_arr.append(data.Content_Lemmatiser_No_Stop_Words[arr][el])\n",
    "    data.Content_Lemmatiser_No_Stop_Words[arr]=tmp_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['carrière',\n",
       " 'artistique',\n",
       " 'artiste',\n",
       " 'multidisciplinaire',\n",
       " 'peinture',\n",
       " 'sculpture',\n",
       " 'photographie',\n",
       " 'vidéo',\n",
       " 'enseigne',\n",
       " 'différent',\n",
       " 'école',\n",
       " 'tel',\n",
       " 'aviv',\n",
       " 'récompenser',\n",
       " 'prix',\n",
       " 'ministère',\n",
       " 'éducation',\n",
       " 'culture',\n",
       " 'prix',\n",
       " 'musée',\n",
       " 'art',\n",
       " 'Petah',\n",
       " 'Tikva',\n",
       " 'œuvre',\n",
       " 'présenter',\n",
       " 'différent',\n",
       " 'musée',\n",
       " 'musée',\n",
       " 'israël',\n",
       " 'Jérusalem',\n",
       " 'mort',\n",
       " 'février',\n",
       " 'site',\n",
       " 'information',\n",
       " 'Mako',\n",
       " 'révéler',\n",
       " 'viser',\n",
       " 'enquête',\n",
       " 'concerner',\n",
       " 'relation',\n",
       " 'sexuel',\n",
       " 'élève',\n",
       " 'mineur',\n",
       " 'lendemain',\n",
       " 'retrouver',\n",
       " 'mort',\n",
       " 'suicider']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Content_Lemmatiser_No_Stop_Words[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('Suicides_wikipedia_scrapping_fr_LEMMATISER_AND_TAGS.csv',encoding='utf-8',sep=';',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
