{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('fr_core_news_md')\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from collections import Counter\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "jar = 'stanford_tagger/stanford-postagger-3.9.2.jar'\n",
    "model = 'stanford_tagger/models/french.tagger'\n",
    "import os\n",
    "java_path = \"C:/Program Files (x86)/Java/jre1.8.0_251/bin/java.exe\"\n",
    "os.environ['JAVAHOME'] = java_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data/Suicides_wikipedia_scrapping_fr_LEMMATISER.csv',encoding='utf-8',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Content_Lemmatiser_No_Stop_Words=[re.sub(\"', '\",' ',el) for el in data.Content_Lemmatiser_No_Stop_Words]\n",
    "data.Content_Lemmatiser_No_Stop_Words=[re.sub(\"\\['\",'',el) for el in data.Content_Lemmatiser_No_Stop_Words]\n",
    "data.Content_Lemmatiser_No_Stop_Words=[re.sub(\"'\\]\",'',el) for el in data.Content_Lemmatiser_No_Stop_Words]\n",
    "data.Content_Lemmatiser_No_Stop_Words=[el.split(' ') for el in data.Content_Lemmatiser_No_Stop_Words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\axelb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\axelb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data.Content)):\n",
    "    if not pd.isnull(data.Content[i]):\n",
    "        data.Content[i]=re.sub('modifier le code ','',data.Content[i])\n",
    "        data.Content[i]=data.Content[i].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('fils', 'NC'), ('Adolfo', 'NPP'), ('couve', 'V'), ('Braga', 'NPP'), ('Clemencia', 'NPP'), ('Rioseco', 'NPP'), ('Fernández', 'NPP'), ('Adolfo', 'NPP'), ('couve', 'V'), ('aîner', 'VINF'), ('trois', 'DET'), ('frère', 'NC'), ('naître', 'VINF'), ('Valparaíso', 'NPP'), ('1940', 'N'), ('passer', 'VINF'), ('enfance', 'NC'), ('Llay', 'NPP'), ('Llay', 'NPP'), ('où', 'PROREL'), ('habite', 'V'), ('jusqu', 'VPP'), ('âge', 'NC'), ('huit', 'ADJ'), ('an', 'NC'), ('avant', 'P'), ('installer', 'VINF'), ('famille', 'NC'), ('santiago', 'ADJ'), ('Chile', 'NPP'), ('achever', 'VINF'), ('scolarité', 'NC'), ('Colegio', 'NPP'), ('san', 'ET'), ('ignacio', 'ET'), ('1958', 'N'), ('enterprend', 'V'), ('premier', 'ADJ'), ('étude', 'NC'), ('artistique', 'ADJ'), ('escuela', 'V'), ('Bellas', 'NPP'), ('Artes', 'NPP'), ('universidad', 'ET'), ('Chile', 'ET'), ('1962', 'N'), ('obtenir', 'VINF'), ('bourse', 'NC'), ('étudier', 'VINF'), ('école', 'DET'), ('beal', 'ADJ'), ('art', 'NC'), ('Paris', 'NPP'), ('année', 'NC'), ('suivre', 'VINF'), ('poursuivre', 'VINF'), ('étude', 'NC'), ('art', 'NC'), ('student', 'V'), ('League', 'DET'), ('New', 'DET'), ('York', 'DET'), ('avoir', 'V'), ('marier', 'VINF'), ('Marta', 'NPP'), ('Carrasco', 'NPP'), ('peintre', 'V'), ('illustrateur', 'ADJ'), ('livre', 'NC'), ('enfer', 'VINF'), ('fille', 'NC'), ('Camila', 'NPP'), ('couve', 'V'), ('née', 'VPP'), ('1963', 'N'), ('fait', 'N'), ('débute', 'V'), ('écriture', 'NC'), ('2018', 'ADJ'), ('publier', 'VINF'), ('estampa', 'V'), ('niña', 'N'), ('Alfaguara', 'N'), ('passer', 'VINF'), ('12', 'DET'), ('dernier', 'ADJ'), ('année', 'NC'), ('vie', 'NC'), ('Carthagène', 'NPP'), ('petit', 'ADJ'), ('ville', 'NC'), ('province', 'NC'), ('saint', 'ADJ'), ('après', 'P'), ('fort', 'ADJ'), ('dépression', 'NC'), ('suicide', 'NC'), ('1998', 'N')]\n"
     ]
    }
   ],
   "source": [
    "pos_tagger = StanfordPOSTagger(model, jar, encoding='utf8' )\n",
    "res = pos_tagger.tag(data.Content_Lemmatiser_No_Stop_Words[0])\n",
    "print (res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-0a5850463f8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mContent_Lemmatiser_No_Stop_Words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mContent_Lemmatiser_No_Stop_Words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'%'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mContent_Lemmatiser_No_Stop_Words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_tagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mContent_Lemmatiser_No_Stop_Words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Temps d execution : %s secondes ---\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tag\\stanford.py\u001b[0m in \u001b[0;36mtag\u001b[1;34m(self, tokens)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;31m# This function should return list of tuple rather than list of list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtag_sents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tag\\stanford.py\u001b[0m in \u001b[0;36mtag_sents\u001b[1;34m(self, sentences)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Run the tagger and get the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         stanpos_output, _stderr = java(\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasspath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stanford_jar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         )\n\u001b[0;32m    118\u001b[0m         \u001b[0mstanpos_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstanpos_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\internals.py\u001b[0m in \u001b[0;36mjava\u001b[1;34m(cmd, classpath, stdin, stdout, stderr, blocking)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mblocking\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;31m# Check the return code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m                 \u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    965\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m                 \u001b[1;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1294\u001b[0m             \u001b[1;31m# calls communicate again.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_remaining_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutExpired\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[1;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1058\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# already determined that the C code is done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "for i in range(len(data.Content_Lemmatiser_No_Stop_Words)):\n",
    "    print(str((i+1)/len(data.Content_Lemmatiser_No_Stop_Words))[:4]+'%')\n",
    "    data.Content_Lemmatiser_No_Stop_Words[i]=pos_tagger.tag(data.Content_Lemmatiser_No_Stop_Words[i])\n",
    "    clear_output(wait=True)\n",
    "print(\"Temps d execution : %s secondes ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [(fils, NC), (Adolfo, NPP), (couve, V), (Braga...\n",
       "1       [(carrière, NC), (artistique, ADJ), (artiste, ...\n",
       "2       [(originaire, ADJ), (kansa, NC), (city, NPP), ...\n",
       "3       [(section, NC), (vide, NC), (insuffisamment, A...\n",
       "4       [(dès, P), (Michel, NPP), (caron, NC), (vouloi...\n",
       "                              ...                        \n",
       "2094    [vie, tragique, œuvre, kazan, symbolisent, dif...\n",
       "2095                                                 [[]]\n",
       "2096                                                 [[]]\n",
       "2097    [naître, Sunpu, humble, origine, yui, passer, ...\n",
       "2098    [Zusho, naître, ville, autour, château, Kagosh...\n",
       "Name: Content_Lemmatiser_No_Stop_Words, Length: 2099, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Content_Lemmatiser_No_Stop_Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [fils, Adolfo, couve, Braga, Clemencia, Riosec...\n",
       "1       [carrière, artistique, artiste, multidisciplin...\n",
       "2       [originaire, kansa, city, Missouri, naître, pè...\n",
       "3       [section, vide, insuffisamment, détaillée, inc...\n",
       "4       [dès, Michel, caron, vouloir, devenir, comédie...\n",
       "                              ...                        \n",
       "2094    [vie, tragique, œuvre, kazan, symbolisent, dif...\n",
       "2095                                                 [[]]\n",
       "2096                                                 [[]]\n",
       "2097    [naître, Sunpu, humble, origine, yui, passer, ...\n",
       "2098    [Zusho, naître, ville, autour, château, Kagosh...\n",
       "Name: Content_Lemmatiser_No_Stop_Words, Length: 2099, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Content_Lemmatiser_No_Stop_Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeped=['NC','N','NPP','ADJ','V','VINF']\n",
    "tri=[\"l'\",'d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d execution : 0.16034340858459473 secondes ---\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "data.Content_Lemmatiser_No_Stop_Words=[ [el for el in tmp if el[1] in keeped] for tmp in data.Content_Lemmatiser_No_Stop_Words]\n",
    "data.Content_Lemmatiser_No_Stop_Words=[ [el for el in tmp if el[0] not in tri] for tmp in data.Content_Lemmatiser_No_Stop_Words]\n",
    "print(\"Temps d execution : %s secondes ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.Content_Lemmatiser_No_Stop_Words=[[el[0] for el in arr] for arr in data.Content_Lemmatiser_No_Stop_Words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=[\"'\",'section','vide','detaillé','incompléte','aide','bienvenue','faire','avoir',\"r\\'\",\"s\\'\",\"d\\'\",\"qu\\'\",\"l\\'\",'année','premier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'\n"
     ]
    }
   ],
   "source": [
    "te=[\"d\\'\",\"qu\\'\",\"d'\",\"l'\",\"l'\"]\n",
    "for i in range(len(te)):\n",
    "    if te[i]  not in stop_words:\n",
    "        print(te[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fils',\n",
       " 'Adolfo',\n",
       " 'couve',\n",
       " 'Braga',\n",
       " 'Clemencia',\n",
       " 'Rioseco',\n",
       " 'Fernández',\n",
       " 'Adolfo',\n",
       " 'couve',\n",
       " 'aîner',\n",
       " 'frère',\n",
       " 'naître',\n",
       " 'Valparaíso',\n",
       " 'passer',\n",
       " 'enfance',\n",
       " 'Llay',\n",
       " 'Llay',\n",
       " 'habite',\n",
       " 'âge',\n",
       " 'huit',\n",
       " 'an',\n",
       " 'installer',\n",
       " 'famille',\n",
       " 'santiago',\n",
       " 'Chile',\n",
       " 'achever',\n",
       " 'scolarité',\n",
       " 'Colegio',\n",
       " 'enterprend',\n",
       " 'étude',\n",
       " 'artistique',\n",
       " 'escuela',\n",
       " 'Bellas',\n",
       " 'Artes',\n",
       " 'obtenir',\n",
       " 'bourse',\n",
       " 'étudier',\n",
       " 'beal',\n",
       " 'art',\n",
       " 'Paris',\n",
       " 'suivre',\n",
       " 'poursuivre',\n",
       " 'étude',\n",
       " 'art',\n",
       " 'student',\n",
       " 'marier',\n",
       " 'Marta',\n",
       " 'Carrasco',\n",
       " 'peintre',\n",
       " 'illustrateur',\n",
       " 'livre',\n",
       " 'enfer',\n",
       " 'fille',\n",
       " 'Camila',\n",
       " 'couve',\n",
       " 'fait',\n",
       " 'débute',\n",
       " 'écriture',\n",
       " 'publier',\n",
       " 'estampa',\n",
       " 'niña',\n",
       " 'Alfaguara',\n",
       " 'passer',\n",
       " 'dernier',\n",
       " 'vie',\n",
       " 'Carthagène',\n",
       " 'petit',\n",
       " 'ville',\n",
       " 'province',\n",
       " 'saint',\n",
       " 'fort',\n",
       " 'dépression',\n",
       " 'suicide']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "save=data.Content_Lemmatiser_No_Stop_Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\axelb\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "tmp=data.Content_Lemmatiser_No_Stop_Words\n",
    "data.Content_Lemmatiser_No_Stop_Words=[[el for el in arr if el not in stop_words] for arr in data.Content_Lemmatiser_No_Stop_Words]\n",
    "for arr in range(len(data.Content_Lemmatiser_No_Stop_Words)):\n",
    "    tmp_arr=[]\n",
    "    for el in range(len(data.Content_Lemmatiser_No_Stop_Words[arr])):\n",
    "        if not data.Content_Lemmatiser_No_Stop_Words[arr][el].isdigit():\n",
    "            tmp_arr.append(data.Content_Lemmatiser_No_Stop_Words[arr][el])\n",
    "    data.Content_Lemmatiser_No_Stop_Words[arr]=tmp_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['carrière',\n",
       " 'artistique',\n",
       " 'artiste',\n",
       " 'multidisciplinaire',\n",
       " 'peinture',\n",
       " 'sculpture',\n",
       " 'photographie',\n",
       " 'vidéo',\n",
       " 'enseigne',\n",
       " 'différent',\n",
       " 'école',\n",
       " 'tel',\n",
       " 'aviv',\n",
       " 'récompenser',\n",
       " 'prix',\n",
       " 'ministère',\n",
       " 'éducation',\n",
       " 'culture',\n",
       " 'prix',\n",
       " 'musée',\n",
       " 'art',\n",
       " 'Petah',\n",
       " 'Tikva',\n",
       " 'œuvre',\n",
       " 'présenter',\n",
       " 'différent',\n",
       " 'musée',\n",
       " 'musée',\n",
       " 'israël',\n",
       " 'Jérusalem',\n",
       " 'mort',\n",
       " 'février',\n",
       " 'site',\n",
       " 'information',\n",
       " 'Mako',\n",
       " 'révéler',\n",
       " 'viser',\n",
       " 'enquête',\n",
       " 'concerner',\n",
       " 'relation',\n",
       " 'sexuel',\n",
       " 'élève',\n",
       " 'mineur',\n",
       " 'lendemain',\n",
       " 'retrouver',\n",
       " 'mort',\n",
       " 'suicider']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Content_Lemmatiser_No_Stop_Words[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('Suicides_wikipedia_scrapping_fr_LEMMATISER_AND_TAGS.csv',encoding='utf-8',sep=';',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
